{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c215225-65bb-48fe-92bb-7810ec7a3c38",
   "metadata": {},
   "source": [
    "<div style=\"background-color:moccasin; color:black; padding:5px; font-size:20px\">\n",
    "Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8a14b-cd1c-42ce-b47a-765952f73d36",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54854e97-82b8-40c1-a549-17fba393e02c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hopsworks\n",
      "  Using cached hopsworks-3.4.4-py3-none-any.whl\n",
      "Collecting hsfs<3.5.0,>=3.4.0 (from hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached hsfs-3.4.7-py3-none-any.whl\n",
      "Collecting hsml<3.5.0,>=3.4.0 (from hopsworks)\n",
      "  Using cached hsml-3.4.6-py3-none-any.whl\n",
      "Collecting pyhumps==1.6.1 (from hopsworks)\n",
      "  Using cached pyhumps-1.6.1-py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from hopsworks) (2.31.0)\n",
      "Collecting furl (from hopsworks)\n",
      "  Using cached furl-2.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from hopsworks) (1.28.64)\n",
      "Collecting pyjks (from hopsworks)\n",
      "  Using cached pyjks-20.0.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: mock in /opt/conda/lib/python3.10/site-packages (from hopsworks) (5.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hopsworks) (4.66.1)\n",
      "Requirement already satisfied: pandas<2.2.0 in /opt/conda/lib/python3.10/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.1.4)\n",
      "Requirement already satisfied: numpy<2 in /opt/conda/lib/python3.10/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.26.3)\n",
      "Collecting avro==1.11.0 (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached avro-1.11.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.4.49)\n",
      "Collecting PyMySQL[rsa] (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting great-expectations==0.14.13 (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached great_expectations-0.14.13-py3-none-any.whl (5.0 MB)\n",
      "Collecting markupsafe<2.1.0 (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached MarkupSafe-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting tzlocal (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.6.0)\n",
      "Collecting altair<5,>=4.0.0 (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Requirement already satisfied: Click>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=3.2 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (42.0.2)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (6.10.0)\n",
      "Requirement already satisfied: Ipython>=7.16.3 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (8.20.0)\n",
      "Collecting jinja2<3.1.0,>=2.10 (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: jsonpatch>=1.22 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.33)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.17.3)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.2)\n",
      "Requirement already satisfied: nbformat>=5.0 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.9.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (23.2)\n",
      "Collecting pyparsing<3,>=2.4 (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2021.3 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.3)\n",
      "Collecting ruamel.yaml<0.17.18,>=0.16 (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached ruamel.yaml-0.17.17-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.11.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.26.18)\n",
      "Collecting pyhopshive[thrift] (from hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached PyHopsHive-0.6.4.1.dev0-py3-none-any.whl\n",
      "Requirement already satisfied: pyarrow>=10.0 in /opt/conda/lib/python3.10/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (12.0.1)\n",
      "Collecting confluent-kafka<=2.3.0 (from hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting fastavro<=1.8.2,>=1.4.11 (from hsfs[python]<3.5.0,>=3.4.0->hopsworks)\n",
      "  Using cached fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->hopsworks) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->hopsworks) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->hopsworks) (2023.11.17)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.64 in /opt/conda/lib/python3.10/site-packages (from boto3->hopsworks) (1.31.64)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from boto3->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: six>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from furl->hopsworks) (1.16.0)\n",
      "Collecting orderedmultidict>=1.0.1 (from furl->hopsworks)\n",
      "  Using cached orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting javaobj-py3 (from pyjks->hopsworks)\n",
      "  Using cached javaobj_py3-0.4.3-py2.py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: pyasn1>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from pyjks->hopsworks) (0.5.1)\n",
      "Requirement already satisfied: pyasn1-modules in /opt/conda/lib/python3.10/site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Collecting pycryptodomex (from pyjks->hopsworks)\n",
      "  Using cached pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting twofish (from pyjks->hopsworks)\n",
      "  Using cached twofish-0.3.0-cp310-cp310-linux_x86_64.whl\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.4)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.18.3)\n",
      "Requirement already satisfied: thrift>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.19.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from altair<5,>=4.0.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.4)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<5,>=4.0.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.2->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.7.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.17.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.14.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch>=1.22->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (23.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.19.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.10/site-packages (from nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.7.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.2->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.2.13)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core->nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.2.2)\n",
      "Using cached confluent_kafka-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "Using cached fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Using cached pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: twofish, pyhumps, javaobj-py3, confluent-kafka, tzlocal, ruamel.yaml, pyparsing, PyMySQL, pycryptodomex, orderedmultidict, markupsafe, fastavro, avro, pyjks, jinja2, furl, pyhopshive, altair, great-expectations, hsml, hsfs, hopsworks\n",
      "  Attempting uninstall: ruamel.yaml\n",
      "    Found existing installation: ruamel.yaml 0.18.5\n",
      "    Uninstalling ruamel.yaml-0.18.5:\n",
      "      Successfully uninstalled ruamel.yaml-0.18.5\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.1\n",
      "    Uninstalling pyparsing-3.1.1:\n",
      "      Successfully uninstalled pyparsing-3.1.1\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 2.1.4\n",
      "    Uninstalling MarkupSafe-2.1.4:\n",
      "      Successfully uninstalled MarkupSafe-2.1.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "  Attempting uninstall: altair\n",
      "    Found existing installation: altair 5.2.0\n",
      "    Uninstalling altair-5.2.0:\n",
      "      Successfully uninstalled altair-5.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask 3.0.1 requires Jinja2>=3.1.2, but you have jinja2 3.0.3 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\n",
      "werkzeug 3.0.1 requires MarkupSafe>=2.1.1, but you have markupsafe 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMySQL-1.1.0 altair-4.2.2 avro-1.11.0 confluent-kafka-2.3.0 fastavro-1.8.2 furl-2.1.3 great-expectations-0.14.13 hopsworks-3.4.4 hsfs-3.4.7 hsml-3.4.6 javaobj-py3-0.4.3 jinja2-3.0.3 markupsafe-2.0.1 orderedmultidict-1.0.1 pycryptodomex-3.20.0 pyhopshive-0.6.4.1.dev0 pyhumps-1.6.1 pyjks-20.0.0 pyparsing-2.4.7 ruamel.yaml-0.17.17 twofish-0.3.0 tzlocal-5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ca1d82-6459-4bd1-84eb-e71b570db6ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.20)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.54.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.11.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.11.17)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: MarkupSafe\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask 3.0.1 requires Jinja2>=3.1.2, but you have jinja2 3.0.3 which is incompatible.\n",
      "hsfs 3.4.7 requires markupsafe<2.1.0, but you have markupsafe 2.1.5 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4dfb24-76b8-47f9-816a-57baa7f6f843",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.12.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.54.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.26.3)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from tensorboard) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.42.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd1764f-d4a1-4cba-bf79-74329ec61001",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_recommenders\n",
      "  Using cached tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow_recommenders) (2.1.0)\n",
      "Requirement already satisfied: tensorflow>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_recommenders) (2.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.10.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (0.4.20)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (1.54.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.42.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow_recommenders) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow_recommenders) (1.11.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow_recommenders) (3.2.2)\n",
      "Installing collected packages: tensorflow_recommenders\n",
      "Successfully installed tensorflow_recommenders-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a122fa67-bcb6-4eef-8f74-f55636dfda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (23.2)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b5626-cc60-4615-9df6-63db43c525cd",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09e8d92-036e-45f1-b18f-1488f4cec3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 19:07:18.738608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup, Normalization\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a119cc8-f295-4f3e-ab98-0f1d97439893",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "import tensorboard\n",
    "log_dir = \"logs/train_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") #  Create Log Dir\n",
    "summary_writer = tf.summary.create_file_writer(log_dir) # Instantiate writer\n",
    "\n",
    "# Tensorboard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce5c01-588c-4e51-b147-e3db200ece01",
   "metadata": {},
   "source": [
    "<div style=\"background-color:moccasin; color:black; padding:5px; font-size:20px\">\n",
    "Hopsworks Feature Store Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0d12a0-befb-4849-9c30-6912a30ed12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize a client for Systems Manager\n",
    "ssm = boto3.client('ssm', region_name='us-east-1')\n",
    "\n",
    "parameter_name = 'hopsworks-api-key'\n",
    "\n",
    "# Fetch the parameter\n",
    "response = ssm.get_parameter(Name=parameter_name, WithDecryption=True)\n",
    "\n",
    "# Extract the parameter value (API key in this case)\n",
    "hopsworks_api_key = response['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9889ef2b-2275-4e3f-8cab-03258c0ae1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/475285\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581d568-e0d5-4d8b-ab78-9682b399eb5f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:moccasin; color:black; padding:5px; font-size:20px\">\n",
    "Training Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8e2cc-9e38-4f2a-be34-30f3d059304c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Create Dataset From Feature Store (Hopsworks)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df2447ac-afa1-46aa-b08c-5dca19c8e484",
   "metadata": {},
   "source": [
    "# Fetch Feature Groups\n",
    "trans_fg = fs.get_feature_group(name=\"transactions\",version=1)\n",
    "customers_fg = fs.get_feature_group(name=\"customers\",version=1)\n",
    "articles_fg = fs.get_feature_group(name=\"articles\",version=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c93290ff-a56f-4fdc-a9ba-b246b60e32b2",
   "metadata": {},
   "source": [
    "# Join Desired Features to Define 'View'\n",
    "selected_features = trans_fg.select([\"customer_id\", \"article_id\", \"t_dat\", \"price\", \"month_sin\", \"month_cos\"])\\\n",
    "    .join(customers_fg.select([\"age\", \"club_member_status\", \"age_group\"]), on=\"customer_id\")\\\n",
    "    .join(articles_fg.select([\"garment_group_name\", \"index_group_name\"]), on=\"article_id\")\n",
    "\n",
    "selected_features.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41351ddd-5935-46ea-aeea-2a0eb48a1374",
   "metadata": {},
   "source": [
    "# Create Retrieval Dataset View\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='retrieval',\n",
    "    query=selected_features,\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a82aec-fd4f-429b-b793-f603f752ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If View Already Created:\n",
    "feature_view = fs.get_feature_view(name='retrieval', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8d546a-8bd1-4e92-9a03-43f570615e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (115.15s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `2`.\n"
     ]
    }
   ],
   "source": [
    "# Fetch Datasets From View Using Hopsworks Train-test Split Function\n",
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e5f25f1-043c-4741-9d42-2b73a681db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"article_id\"] = train_df[\"article_id\"].astype(str)  # to be removed\n",
    "val_df[\"article_id\"] = val_df[\"article_id\"].astype(str)  # to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee884b07-a866-4116-bae3-26e5dd5656f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = [\"customer_id\", \"age\", \"month_sin\", \"month_cos\"]\n",
    "candidate_features = [\"article_id\", \"garment_group_name\", \"index_group_name\"]\n",
    "\n",
    "def df_to_ds(df):\n",
    "    # Convert df to tensoflow dataset\n",
    "    return tf.data.Dataset.from_tensor_slices({col : df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "val_ds = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10952919-592e-4b95-b91f-81e95b1975a9",
   "metadata": {},
   "source": [
    "Creating unique-element lists for categorical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990c1271-b80e-4ecb-8257-0000fdab2f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 433,927\n",
      "Number of users: 131,880\n",
      "Number of items: 24,621\n",
      "['Dressed', 'Jersey Basic', 'Blouses', 'Knitwear', 'Jersey Fancy', 'Trousers Denim', 'Swimwear', 'Trousers', 'Socks and Tights', 'Shoes', 'Skirts', 'Dresses Ladies', 'Accessories', 'Outdoor', 'Under-, Nightwear', 'Special Offers', 'Shirts', 'Dresses/Skirts girls', 'Shorts', 'Unknown', 'Woven/Jersey/Knitted mix Baby']\n"
     ]
    }
   ],
   "source": [
    "user_id_list = train_df[\"customer_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"article_id\"].unique().tolist()\n",
    "\n",
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()\n",
    "\n",
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")\n",
    "print(garment_group_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4c8d7-a2ff-47cf-8369-d9cd23e80f78",
   "metadata": {},
   "source": [
    "<div style=\"background-color:moccasin; color:black; padding:5px; font-size:20px\">\n",
    "Retrieval Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1704ba5-16b1-486a-816e-98fca064627f",
   "metadata": {},
   "source": [
    "FactorizedTopK:\n",
    "- Positive samples are only ones associated with the INDIVIDUAL query record. It does not reward for retrieving an item associated with the user on a separate record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1759143-667f-436d-97d4-d8b4f82bd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0351a6-2471-4573-9a05-9a69aaa2c9ec",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Query Tower Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4267b091-882b-4178-b8ac-4e24342aff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # user_embedding: Integer-Encoding\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                EMB_DIM\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # age: Normalization\n",
    "        self.normalized_age = Normalization(axis=None)\n",
    "        \n",
    "        # Embedding Layer Definition\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMB_DIM, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMB_DIM)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Concat respectively transformed inputs\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"customer_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            tf.reshape(inputs[\"month_sin\"], (-1,1)),\n",
    "            tf.reshape(inputs[\"month_cos\"], (-1,1))\n",
    "        ], axis=1)\n",
    "\n",
    "        # Send through embedding layer\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e39beb-93b5-4f0f-a4f4-c2471a20f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 19:27:09.256283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [433927]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-02-16 19:27:09.257085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype double and shape [433927]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2024-02-16 19:27:19.896005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [433927]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-0.11535659, -0.38656187, -0.02634433, -0.20807752, -0.4647346 ,\n",
       "        -0.22234225,  0.09918011,  0.07456864, -0.24407706, -0.13969278,\n",
       "         0.07337382,  0.0697898 ,  0.17010647, -0.16232108,  0.12789005,\n",
       "        -0.01841322]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Model\n",
    "query_model = QueryTower()\n",
    "\n",
    "# Computing dataset-wide stats for normalization\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Model Inputs:\n",
    "query_df = train_df[query_features] # Subset to query feats\n",
    "query_ds = df_to_ds(query_df).batch(1) # convert df to tf dataset\n",
    "\n",
    "# load inputs into model\n",
    "query_model(next(iter(query_ds))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3911b3-8539-4abf-be72-deb03ab3d9b5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Item Tower Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b049a99-e89a-4bd5-80ca-41d1f6e879e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=item_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # We add an additional embedding to account for unknown tokens.\n",
    "                len(item_id_list) + 1,\n",
    "                EMB_DIM\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.garment_group_tokenizer = StringLookup(vocabulary=garment_group_list, mask_token=None)\n",
    "        self.index_group_tokenizer = StringLookup(vocabulary=index_group_list, mask_token=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(EMB_DIM, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(EMB_DIM)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        garment_group_embedding = tf.one_hot(\n",
    "            self.garment_group_tokenizer(inputs[\"garment_group_name\"]),\n",
    "            len(garment_group_list)\n",
    "        )\n",
    "\n",
    "        index_group_embedding = tf.one_hot(\n",
    "            self.index_group_tokenizer(inputs[\"index_group_name\"]),\n",
    "            len(index_group_list)\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.item_embedding(inputs[\"article_id\"]),\n",
    "            garment_group_embedding,\n",
    "            index_group_embedding\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53f32932-9b6c-41a3-9784-b38e46911cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "item_model = ItemTower()\n",
    "\n",
    "# Model Inputs:\n",
    "item_df = train_df[candidate_features] # Subset to item feats\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True) # Drop dup col\n",
    "item_ds = df_to_ds(item_df) # Convert to tf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f57cc7-021d-467a-90bc-542b7010948b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:teal; color:white; padding:5px; font-size:20px\">\n",
    "Two Tower Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ae1b0b-f18e-4585-b166-3e3b03d2f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, query_model, item_model):\n",
    "        super().__init__()\n",
    "        self.query_model = query_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            \n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                # Grab the batch of items and retrieve embeddings\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.query_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(\n",
    "                user_embeddings, \n",
    "                item_embeddings,\n",
    "                compute_metrics=False, # Skip summary statistics\n",
    "            )\n",
    "\n",
    "            # Handles regularization if it has been applied \n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables) # Calculate gradients\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables)) # update weights\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.query_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(\n",
    "            user_embeddings, \n",
    "            item_embeddings,\n",
    "            compute_metrics=False,\n",
    "        )\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4d4dd-f63a-46c5-aa79-5a2908ab4a19",
   "metadata": {},
   "source": [
    "<div style=\"background-color: darkgreen ; color:white; padding:0px; font-size:15px\">\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a185f2cf-8bb8-4816-9884-920512308148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "model = TwoTowerModel(query_model, item_model)\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(0.001, learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "248d583a-2b98-48ef-b931-a0e0aecfa8a1",
   "metadata": {},
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdc7ff07-3682-4038-9bb8-2a817b18a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 19:28:35.166749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype string and shape [433927]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-02-16 19:28:35.168066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype string and shape [433927]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "212/212 [==============================] - ETA: 0s - loss: 15446.1301 - regularization_loss: 0.0000e+00 - total_loss: 15446.1301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 19:29:45.655624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [54240]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 73s 321ms/step - loss: 15445.6679 - regularization_loss: 0.0000e+00 - total_loss: 15445.6679 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 6608.5181 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6608.5181\n",
      "Epoch 2/5\n",
      "212/212 [==============================] - 68s 319ms/step - loss: 14496.8359 - regularization_loss: 0.0000e+00 - total_loss: 14496.8359 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 6543.5801 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6543.5801\n",
      "Epoch 3/5\n",
      "212/212 [==============================] - 68s 320ms/step - loss: 13515.1308 - regularization_loss: 0.0000e+00 - total_loss: 13515.1308 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 6451.3472 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6451.3472\n",
      "Epoch 4/5\n",
      "212/212 [==============================] - 67s 317ms/step - loss: 12538.9692 - regularization_loss: 0.0000e+00 - total_loss: 12538.9692 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 6493.3481 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6493.3481\n",
      "Epoch 5/5\n",
      "212/212 [==============================] - 67s 318ms/step - loss: 11830.1524 - regularization_loss: 0.0000e+00 - total_loss: 11830.1524 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 6744.0303 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6744.0303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2d759c700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee09ff-ed5b-4883-8813-c0b1e789d154",
   "metadata": {},
   "source": [
    "<div style=\"background-color:moccasin; color:black; padding:5px; font-size:20px\">\n",
    "Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65abe1-88e2-40a4-9a35-8c5550850b38",
   "metadata": {},
   "source": [
    "<div style=\"background-color: darkgreen ; color:white; padding:0px; font-size:15px\">\n",
    "Local Saves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317bf49-3402-4c00-b4e4-6a769bb3b57d",
   "metadata": {},
   "source": [
    "The code below wraps the model in a module so that the raw input can be returned along with the embedding of a given input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8e593f1-6e68-4910-86d2-17cf5f8250ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModelModule(tf.Module):\n",
    "    def __init__(self, query_model):\n",
    "        self.query_model = query_model\n",
    "\n",
    "    @tf.function() # Decorator allowing for input specification\n",
    "    # Takes in user data and returns embedding + user data\n",
    "    def compute_emb(self, instances):\n",
    "        query_emb = self.query_model(instances)\n",
    "        return {\"customer_id\": instances[\"customer_id\"],\n",
    "                \"month_sin\": instances[\"month_sin\"],\n",
    "                \"month_cos\": instances[\"month_cos\"],\n",
    "                \"query_emb\": query_emb}\n",
    "\n",
    "\n",
    "# Wrap only the Query Tower model into new QueryModelModule\n",
    "query_model = QueryModelModule(model.query_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f57fbd-7bdd-414f-b7b9-f22a2c5f3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_model/assets\n",
      "2024-02-16 20:37:25,230 INFO: Assets written to: query_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Define input specifications\n",
    "instances_spec={\n",
    "    'customer_id': tf.TensorSpec(shape=(None,), dtype=tf.string, name='customer_id'),\n",
    "    'month_sin': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='month_sin'),\n",
    "    'month_cos': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='month_cos'),\n",
    "    'age': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='age')\n",
    "}\n",
    "# Apply input specs to compute_embed()\n",
    "signatures = query_model.compute_emb.get_concrete_function(instances_spec)\n",
    "\n",
    "# Save ModelModule w/ signature\n",
    "tf.saved_model.save(query_model, \"model_artifacts/query_model\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a65897c-d377-45af-aa44-f878ab33d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: candidate_model/assets\n",
      "2024-02-16 20:38:28,511 INFO: Assets written to: candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model Locally\n",
    "tf.saved_model.save(model.item_model, \"model_artifacts/candidate_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f295808-c67b-44e4-a7cf-5a8f02bffb06",
   "metadata": {},
   "source": [
    "<div style=\"background-color: darkgreen ; color:white; padding:0px; font-size:15px\">\n",
    "Save To Model Registry (Hopsworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36006a4a-aae7-4d1a-81ff-7a1f935893ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hsml\n",
    "\n",
    "# Connect to Hopsworks Model Registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d16c40e-e655-4064-bd21-36bdd2fde494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'columnar_schema': [{'name': 'customer_id',\n",
       "    'type': 'object'},\n",
       "   {'name': 'age', 'type': 'float64'},\n",
       "   {'name': 'month_sin', 'type': 'float64'},\n",
       "   {'name': 'month_cos', 'type': 'float64'}]},\n",
       " 'output_schema': {'tensor_schema': [{'name': 'query_embedding',\n",
       "    'shape': '[16]',\n",
       "    'type': 'float32'}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Infer input schema from data.\n",
    "query_model_input_schema = Schema(query_df)\n",
    "\n",
    "# Manually specify output schema.\n",
    "query_model_output_schema = Schema([{\n",
    "    \"name\": \"query_embedding\",\n",
    "    \"type\": \"float32\",\n",
    "    \"shape\": [EMB_DIM]\n",
    "}])\n",
    "\n",
    "query_model_schema = ModelSchema(\n",
    "    input_schema=query_model_input_schema,\n",
    "    output_schema=query_model_output_schema\n",
    ")\n",
    "\n",
    "query_model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f254173c-8de0-4a06-b8fb-e81f7199042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28790df2ae54a40aa567013b5893d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f855a3b1668848b0bc6683a5869caeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/56 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414b503888c34f4695ed8a7ca8b3203f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/9927478 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf2e89c4b5a4053805024e12f695a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/8448652 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffda1cf44cbe43f98b12c048231107a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/583 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e94494c8414fe488b44d1005c61de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/155 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221b4cc4cd78470cad6a5dbe58844d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/497 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/475285/models/query_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'query_model', version: 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_example = query_df.sample().to_dict(\"records\")\n",
    "\n",
    "mr_query_model = mr.tensorflow.create_model(\n",
    "    name=\"query_model\",\n",
    "    description=\"Model that generates query embeddings from user and transaction features\",\n",
    "    input_example=query_example,\n",
    "    model_schema=query_model_schema,\n",
    ")\n",
    "mr_query_model.save(\"query_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea835842-a68e-4ac9-a8b0-09c601844e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2622eeb893c4f14a005b8c591f763f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898d5b48c0344819b8b7f522d60bafec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/58 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b287a87d14a16a536d57374b7a105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/623601 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcaea2589d74d218f2854c6b4ae2519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1585410 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d87ba98dcb0466c9c502a022c83f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/424 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cb5a93591641bf9629ac2983587ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/106 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff27c4cae8f74883864d4fb053a4a2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/448 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/475285/models/candidate_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'candidate_model', version: 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_model_input_schema = Schema(item_df)\n",
    "\n",
    "candidate_model_output_schema = Schema([{\n",
    "    \"name\": \"candidate_embedding\",\n",
    "    \"type\": \"float32\",\n",
    "    \"shape\": [EMB_DIM],\n",
    "}])\n",
    "\n",
    "candidate_model_schema = ModelSchema(\n",
    "    input_schema=candidate_model_input_schema,\n",
    "    output_schema=candidate_model_output_schema\n",
    ")\n",
    "\n",
    "candidate_example = item_df.sample().to_dict(\"records\")\n",
    "\n",
    "mr_candidate_model = mr.tensorflow.create_model(\n",
    "    name=\"candidate_model\",\n",
    "    description=\"Model that generates candidate embeddings from item features\",\n",
    "    input_example=candidate_example,\n",
    "    model_schema=candidate_model_schema,\n",
    ")\n",
    "mr_candidate_model.save(\"candidate_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
